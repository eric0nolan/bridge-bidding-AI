{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from sys import getsizeof\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import normalize, Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the csv file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n",
      "30000\n",
      "30000\n",
      "120000\n"
     ]
    }
   ],
   "source": [
    "######### Use pandas to read \"bridge.csv\",\"combats.csv\" file #########\n",
    "\n",
    "\n",
    "bridge_dfN = pd.read_csv('N.csv')\n",
    "bridge_dfS = pd.read_csv('S.csv')  \n",
    "bridge_dfE = pd.read_csv('E.csv')  \n",
    "bridge_dfW = pd.read_csv('W.csv')\n",
    "\n",
    "#bridge_dfN = pd.DataFrame(df_N)\n",
    "#bridge_dfS = pd.DataFrame(df_S)\n",
    "#bridge_dfE = pd.DataFrame(df_E)\n",
    "#bridge_dfW = pd.DataFrame(df_W)\n",
    "\n",
    "bridge_dfN = bridge_dfN[:30000]\n",
    "bridge_dfS = bridge_dfS[:30000]\n",
    "bridge_dfE = bridge_dfE[:30000]\n",
    "bridge_dfW = bridge_dfW[:30000]\n",
    "\n",
    "bridge_dfN = bridge_dfN.drop('lin_file',axis = 1)\n",
    "bridge_dfN = bridge_dfN.drop('board_num',axis = 1)\n",
    "bridge_dfS = bridge_dfS.drop('lin_file',axis = 1)\n",
    "bridge_dfS = bridge_dfS.drop('board_num',axis = 1)\n",
    "bridge_dfE = bridge_dfE.drop('lin_file',axis = 1)\n",
    "bridge_dfE = bridge_dfE.drop('board_num',axis = 1)\n",
    "bridge_dfW = bridge_dfW.drop('lin_file',axis = 1)\n",
    "bridge_dfW = bridge_dfW.drop('board_num',axis = 1)\n",
    "\n",
    "\n",
    "bridge_dfN['direction'] = 'N'\n",
    "bridge_dfS['direction'] = 'S'\n",
    "bridge_dfE['direction'] = 'E'\n",
    "bridge_dfW['direction'] = 'W'\n",
    "'''\n",
    "bridge_dfN_test = bridge_dfN[500000:505000]\n",
    "bridge_dfS_test = bridge_dfS[500000:505000]\n",
    "bridge_dfE_test = bridge_dfE[500000:505000]\n",
    "bridge_dfW_test = bridge_dfW[500000:505000]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bridge_df = pd.concat([bridge_dfN, bridge_dfS], ignore_index=True)\n",
    "bridge_df = pd.concat([bridge_df, bridge_dfE], ignore_index=True)\n",
    "bridge_df = pd.concat([bridge_df, bridge_dfW], ignore_index=True)\n",
    "#bridge_df = bridge_df.astype('int')\n",
    "#df = pd.read_csv('combats.csv') \n",
    "#combats_df = df\n",
    "#print(combats_df.iloc[:,:])\n",
    "#print(len(combats_df.iloc[:,:]))\n",
    "print(len(bridge_dfN.iloc[:,:]))\n",
    "print(len(bridge_dfS.iloc[:,:]))\n",
    "print(len(bridge_dfE.iloc[:,:]))\n",
    "print(len(bridge_dfW.iloc[:,:]))\n",
    "\n",
    "print(len(bridge_df.iloc[:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "aaa = [1, 2, 3]\n",
    "bbb = [4, 5, 6]\n",
    "test.append(aaa)\n",
    "test.append(bbb)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(bridge_dfW)  #set seq = 30num\n",
    "\n",
    "train_data = []\n",
    "train_data_without_feature = []\n",
    "\n",
    "for i in range(len(bridge_df.iloc[:,:])):\n",
    "    if bridge_df.iloc[i,1] == 'none':\n",
    "        bridge_df.iloc[i,1] = 0\n",
    "    elif bridge_df.iloc[i,1] == 'NS':\n",
    "        bridge_df.iloc[i,1] = 1\n",
    "    elif bridge_df.iloc[i,1] == 'EW':\n",
    "        bridge_df.iloc[i,1] = 2\n",
    "    elif bridge_df.iloc[i,1] == 'both':\n",
    "        bridge_df.iloc[i,1] = 3\n",
    "    \n",
    "    temp_list = []\n",
    "    without_feature = []\n",
    "    temp_list.append(bridge_df.iloc[i,0])\n",
    "    without_feature.append(bridge_df.iloc[i,0])\n",
    "    temp_list.append(bridge_df.iloc[i,1])\n",
    "    without_feature.append(bridge_df.iloc[i,1])\n",
    "    temp_list.append(bridge_df.iloc[i,2])\n",
    "    without_feature.append(bridge_df.iloc[i,2])\n",
    "    temp_list.append(bridge_df.iloc[i,3])\n",
    "    without_feature.append(bridge_df.iloc[i,3])\n",
    "    temp_list.append(bridge_df.iloc[i,5])\n",
    "    without_feature.append(bridge_df.iloc[i,5])\n",
    "\n",
    "    split_list6 = bridge_df.iloc[i,6].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list6[j])\n",
    "    '''\n",
    "    split_list7 = bridge_df.iloc[i,7].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list7[j])\n",
    "    '''\n",
    "    split_list9 = bridge_df.iloc[i,9].split('|')    \n",
    "    for j in range(4):\n",
    "        suit = [0]*13\n",
    "        for k in range(len(split_list9[j])):\n",
    "            if split_list9[j][k] == 'A':\n",
    "                suit[1] = 1\n",
    "            elif split_list9[j][k] == 'K':\n",
    "                suit[0] = 1\n",
    "            elif split_list9[j][k] == 'Q':\n",
    "                suit[12] = 1\n",
    "            elif split_list9[j][k] == 'J':\n",
    "                suit[11] = 1\n",
    "            elif split_list9[j][k] == 'T':\n",
    "                suit[10] = 1\n",
    "            elif split_list9[j][k].isdigit():\n",
    "                suit[int(split_list9[j][k])] = 1\n",
    "            else:\n",
    "                suit[k] = -1\n",
    "        without_feature = without_feature + suit\n",
    "        temp_list = temp_list + suit\n",
    "\n",
    "    split_list10 = bridge_df.iloc[i,10].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list10[j])\n",
    "    temp_list.append(bridge_df.iloc[i,11])\n",
    "\n",
    "    split_list12 = bridge_df.iloc[i,12].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list12[j])\n",
    "    split_list13 = bridge_df.iloc[i,13].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list13[j])\n",
    "    split_list14 = bridge_df.iloc[i,14].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list14[j])\n",
    "    split_list15 = bridge_df.iloc[i,15].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list15[j])\n",
    "\n",
    "    temp_list.append(bridge_df.iloc[i,16])\n",
    "    temp_list.append(bridge_df.iloc[i,17])\n",
    "    if(bridge_df.iloc[i,18] == 'N'):\n",
    "        temp_list.append(0)\n",
    "    elif(bridge_df.iloc[i,18] == 'S'):\n",
    "        temp_list.append(1)\n",
    "    elif(bridge_df.iloc[i,18] == 'E'):\n",
    "        temp_list.append(2)\n",
    "    elif(bridge_df.iloc[i,18] == 'W'):\n",
    "        temp_list.append(3)\n",
    "    else:\n",
    "        temp_list.append(-1)\n",
    "        \n",
    "    order = bridge_df.iloc[i,5]\n",
    "    #print('order:', order)\n",
    "    split_list = bridge_df.iloc[i,4].split('|')\n",
    "    #print('len: ', len(split_list))\n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence\n",
    "    #example = []\n",
    "    \n",
    "    for ex in range(add_bidding):\n",
    "        temp = 0\n",
    "        temp_list_bidding =[-1]*12\n",
    "        end_1 = ex*4 + order - 1 # split_list[end_1] is the bidding choice of this player in this round \n",
    "        #print('end_1: ', end_1)\n",
    "        #lenth_1 = len(split_list)-1\n",
    "        for j in range(end_1):\n",
    "            if(j>11):\n",
    "                break\n",
    "            split_list[end_1-j-1] = split_list[end_1-j-1].replace(\"!\", \"\")\n",
    "            #print(split_list[end_1-j-1])\n",
    "            if(split_list[end_1-j-1][0]=='p' or split_list[end_1-j-1][0]=='P'):\n",
    "                temp_list_bidding[11-j]=0\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='d' or split_list[end_1-j-1][0]=='D'):\n",
    "                temp_list_bidding[11-j]=36\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='r' or split_list[end_1-j-1][0]=='R'):\n",
    "                temp_list_bidding[11-j]=37\n",
    "                continue\n",
    "\n",
    "\n",
    "            temp = 0\n",
    "            if(len(split_list[end_1-j-1]) != 2):\n",
    "                temp = -1\n",
    "                break\n",
    "            if(split_list[end_1-j-1][0].isdigit()):\n",
    "                temp += (int(split_list[end_1-j-1][0])-1)*5\n",
    "            if(split_list[end_1-j-1][1] == 'C' or split_list[end_1-j-1][1] == 'c'):\n",
    "                temp += 1\n",
    "            elif(split_list[end_1-j-1][1] == 'D' or split_list[end_1-j-1][1] == 'd' ):\n",
    "                temp += 2\n",
    "            elif(split_list[end_1-j-1][1] == 'H' or split_list[end_1-j-1][1] == 'h'):\n",
    "                temp += 3\n",
    "            elif(split_list[end_1-j-1][1] == 'S' or split_list[end_1-j-1][1] == 's'):\n",
    "                temp += 4\n",
    "            elif(split_list[end_1-j-1][1] == 'N' or split_list[end_1-j-1][1] == 'n'):\n",
    "                temp += 5\n",
    "            else:\n",
    "                temp = -1\n",
    "                break\n",
    "            temp_list_bidding[11-j] = temp\n",
    "            \n",
    "        example = temp_list.copy()\n",
    "        example_without_fea =  without_feature.copy()\n",
    "        for j in range(12):\n",
    "            example.append(temp_list_bidding[j])\n",
    "            example_without_fea.append(temp_list_bidding[j])\n",
    "        train_data.append(example)\n",
    "        train_data_without_feature.append(example_without_fea)\n",
    "        \n",
    "train_data = np.asarray(train_data)\n",
    "train_data_without_feature = np.asarray(train_data_without_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.astype('float')\n",
    "train_data_without_feature = train_data_without_feature.astype('float')\n",
    "#np.savetxt('./data/train_data_savefile_back12_orig_30000.txt', train_data, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = train_data.copy()\n",
    "train_without_feature_orig = train_data_without_feature.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig_2 = train_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = np.loadtxt('./data/train_data_savefile_back12_orig_30000.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.   0.   9.   0.   0. ]\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.   0.   9.   0.   0. ]\n",
      "(341553, 97)\n"
     ]
    }
   ],
   "source": [
    "print(train_orig[0])\n",
    "print(train_orig[1])\n",
    "#print(train_orig_2[0])\n",
    "#print(train_orig_2[1])\n",
    "print(train_data[0])\n",
    "print(train_data[1])\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341553, 97)\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.   1.   4.  36.  37. ]\n",
      "0.0\n",
      "[3. 3. 4. 3.]\n",
      "12.0\n",
      "[0.  2.5 1.  0. ]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1.  1.  4. 36. 37.]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_data[3])\n",
    "print(train_data[3][2])\n",
    "print(train_data[3][5:9])\n",
    "print(train_data[3][65])\n",
    "print(train_data[3][78:82])\n",
    "print(train_data[3][85:97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(train_data)\n",
    "train_data_onlyfeature  = np.zeros((l,22))#only contain 2 3 6 8 12 features in our paper\n",
    "for i in range(l):\n",
    "    train_data_onlyfeature[i][0] = train_data[i][2]\n",
    "    train_data_onlyfeature[i][1:5] = train_data[i][5:9]\n",
    "    train_data_onlyfeature[i][5] = train_data[i][65]\n",
    "    train_data_onlyfeature[i][6:10] = train_data[i][78:82]\n",
    "    train_data_onlyfeature[i][10:23] = train_data[i][85:97]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341553, 22)\n",
      "[ 0.   3.   3.   4.   3.  12.   0.   2.5  1.   0.  -1.  -1.  -1.  -1.\n",
      "  1.   4.  36.  37.   0.   0.   6.   9. ]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_onlyfeature.shape)\n",
    "print(train_data_onlyfeature[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.20889319  0.20889319  0.27852425  0.20889319  0.83557275\n",
      "   0.          0.17407766  0.06963106  0.         -0.06963106 -0.06963106\n",
      "  -0.06963106 -0.06963106 -0.06963106 -0.06963106 -0.06963106 -0.06963106\n",
      "  -0.06963106 -0.06963106 -0.06963106 -0.06963106]]\n",
      "[ 0.          0.20889319  0.20889319  0.27852425  0.20889319  0.83557275\n",
      "  0.          0.17407766  0.06963106  0.         -0.06963106 -0.06963106\n",
      " -0.06963106 -0.06963106 -0.06963106 -0.06963106 -0.06963106 -0.06963106\n",
      " -0.06963106 -0.06963106 -0.06963106 -0.06963106]\n",
      "[[ 0.04941662  0.24708311  0.19766648  0.09883324  0.09883324  0.54358283\n",
      "   0.12354155  0.04941662  0.02470831  0.         -0.04941662 -0.04941662\n",
      "  -0.04941662 -0.04941662 -0.04941662 -0.04941662 -0.04941662  0.\n",
      "   0.19766648  0.39533297  0.59299945  0.        ]]\n",
      "[ 0.04941662  0.24708311  0.19766648  0.09883324  0.09883324  0.54358283\n",
      "  0.12354155  0.04941662  0.02470831  0.         -0.04941662 -0.04941662\n",
      " -0.04941662 -0.04941662 -0.04941662 -0.04941662 -0.04941662  0.\n",
      "  0.19766648  0.39533297  0.59299945  0.        ]\n",
      "Normalizer(copy=True, norm='l2')\n",
      "(341553, 22)\n",
      "[ 0.   3.   3.   4.   3.  12.   0.   2.5  1.   0.  -1.  -1.  -1.  -1.\n",
      " -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      "[ 1.   5.   4.   2.   2.  11.   2.5  1.   0.5  0.  -1.  -1.  -1.  -1.\n",
      " -1.  -1.  -1.   0.   4.   8.  12.   0. ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_data = normalize(train_data, axis=0, norm='l2')\n",
    "normalizer = Normalizer(norm='l2').fit(train_data_onlyfeature)\n",
    "train_norm = normalizer.transform(train_data_onlyfeature)\n",
    "print(normalizer.transform(train_data_onlyfeature[0].reshape(1, -1)))\n",
    "print(train_norm[0])\n",
    "print(normalizer.transform(train_data_onlyfeature[115000].reshape(1, -1)))\n",
    "print(train_norm[115000])\n",
    "print(normalizer)\n",
    "print(train_data_onlyfeature.shape)\n",
    "print(train_data_onlyfeature[0])\n",
    "print(train_data_onlyfeature[115000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"normalizer = Normalizer(norm='l2').fit(train_data_without_feature)\\ntrain_without_feature_norm = normalizer.transform(train_data_without_feature)\\nprint(normalizer.transform(train_data_without_feature[0].reshape(1, -1)))\\nprint(train_without_feature_norm[0])\\nprint(normalizer.transform(train_data_without_feature[115000].reshape(1, -1)))\\nprint(train_without_feature_norm[115000])\\nprint(normalizer)\\nprint(train_data_without_feature.shape)\\nprint(train_data_without_feature[0])\\nprint(train_data_without_feature[115000])\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''normalizer = Normalizer(norm='l2').fit(train_data_without_feature)\n",
    "train_without_feature_norm = normalizer.transform(train_data_without_feature)\n",
    "print(normalizer.transform(train_data_without_feature[0].reshape(1, -1)))\n",
    "print(train_without_feature_norm[0])\n",
    "print(normalizer.transform(train_data_without_feature[115000].reshape(1, -1)))\n",
    "print(train_without_feature_norm[115000])\n",
    "print(normalizer)\n",
    "print(train_data_without_feature.shape)\n",
    "print(train_data_without_feature[0])\n",
    "print(train_data_without_feature[115000])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_org = train_data\n",
    "train_data_backup = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.        0.208893  0.208893  0.278524  0.208893  0.835573  0.\n",
      "  0.174078  0.069631  0.       -0.069631 -0.069631 -0.069631 -0.069631\n",
      " -0.069631 -0.069631 -0.069631 -0.069631 -0.069631 -0.069631 -0.069631\n",
      " -0.069631]\n",
      "[ 0.023754  0.071262  0.047508  0.071262  0.11877   0.380065  0.035631\n",
      "  0.        0.        0.11877  -0.023754 -0.023754 -0.023754 -0.023754\n",
      " -0.023754 -0.023754 -0.023754  0.11877   0.855145  0.166278  0.\n",
      "  0.190032]\n",
      "[[ 0.        0.208893  0.208893 ... -0.069631 -0.069631 -0.069631]\n",
      " [ 0.        0.178253  0.178253 ...  0.534758  0.        0.      ]\n",
      " [ 0.        0.208893  0.208893 ... -0.069631 -0.069631 -0.069631]\n",
      " ...\n",
      " [ 0.041739  0.166957  0.041739 ...  0.125218  0.584349  0.709566]\n",
      " [ 0.02741   0.10964   0.02741  ...  0.520792  0.        0.548202]\n",
      " [ 0.019292  0.077166  0.019292 ...  0.462996  0.        0.540162]]\n",
      "(341553, 22)\n"
     ]
    }
   ],
   "source": [
    "#np.savetxt('./data/train_data_savefile_back12_onlyfeature_30000.txt', train_norm, fmt='%f')\n",
    "train_data = []\n",
    "train_data = np.loadtxt('./data/train_data_savefile_back12_onlyfeature_30000.txt', dtype=float)#after normalize\n",
    "#train_data = np.loadtxt('./data/train_data_savefile_back12_30000.txt', dtype=float)\n",
    "print(train_data[0])\n",
    "print(train_data[999])\n",
    "print(train_data)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341553, 97)\n",
      "[ 1.   0.   0.   0.   1.   3.   3.   4.   3.   0.   0.   0.   0.   0.\n",
      "  1.   1.   0.   0.   0.   0.   1.   0.   0.   1.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   1.   1.   0.   0.   0.   0.   1.   0.   1.\n",
      "  1.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "  0.   0.   0.   0.   1.   1.   7.   2.   2.  12.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   2.5  1.   0.   3.5  1.\n",
      "  0.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      "[ 0.05847053  0.          0.          0.          0.05847053  0.1754116\n",
      "  0.1754116   0.23388214  0.1754116   0.          0.          0.\n",
      "  0.          0.          0.05847053  0.05847053  0.          0.\n",
      "  0.          0.          0.05847053  0.          0.          0.05847053\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.05847053  0.05847053  0.\n",
      "  0.          0.          0.          0.05847053  0.          0.05847053\n",
      "  0.05847053  0.          0.          0.          0.          0.05847053\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.05847053  0.05847053  0.          0.          0.          0.\n",
      "  0.05847053  0.05847053  0.40929374  0.11694107  0.11694107  0.70164642\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.14617634  0.05847053  0.          0.20464687  0.05847053\n",
      "  0.         -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053\n",
      " -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053 -0.05847053\n",
      " -0.05847053]\n"
     ]
    }
   ],
   "source": [
    "train_data_with = np.loadtxt('./data/train_data_savefile_back12_30000.txt', dtype=float)\n",
    "train_data_with = np.loadtxt('./data/train_data_savefile_back12_orig_30000.txt', dtype=float)\n",
    "train_norm_with = normalizer.transform(train_data_with)\n",
    "print(train_data_with.shape)\n",
    "print(train_data_with[0])\n",
    "print(train_norm_with[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "train_data[:,0] = train_data[:,0]/50\n",
    "train_data[:,1] = train_data[:,1]/3\n",
    "train_data[:,4:15] = train_data[:,4:15]/37\n",
    "train_data[:,16] = train_data[:,16]/4\n",
    "train_data[:,17:20] = train_data[:,17:20]/13\n",
    "train_data[:,73:76] = train_data[:,73:76]/13\n",
    "train_data[:,81] = train_data[:,81]/30\n",
    "train_data[:,91:94] = train_data[:,91:94]/10\n",
    "train_data[:,95] = train_data[:,95]/10\n",
    "train_data[:,96] = train_data[:,96]/10\n",
    "\n",
    "train_data[:,0] = train_data[:,0]*50\n",
    "train_data[:,1] = train_data[:,1]*3\n",
    "train_data[:,4] = train_data[:,4]*2000\n",
    "train_data[:,5] = train_data[:,5]*4\n",
    "train_data[:,6:13] = train_data[:,6:13]*13\n",
    "train_data[:,66:69] = train_data[:,66:69]*13\n",
    "train_data[:,70] = train_data[:,70]*30\n",
    "train_data[:,83:86] = train_data[:,83:86]*10\n",
    "train_data[:,87] = train_data[:,87]*10\n",
    "'''\n",
    "print(train_data[0,:])\n",
    "print(train_data)\n",
    "print(train_data.shape)\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make one-hot format labels (But bridge seems to use 13-hot-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "341553\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "#train_labels[i][1]:\n",
    "#combats_df.iloc[:,2]\n",
    "\n",
    "combats_train_hot_label = [[0 for x in range(38)] for y in range(len(train_data))]\n",
    "print(type(combats_train_hot_label))\n",
    "t = 0\n",
    "\n",
    "for i in range(len(bridge_df.iloc[:,:])):\n",
    "    split_list = bridge_df.iloc[i,4].split('|')\n",
    "    order = bridge_df.iloc[i,5]\n",
    "    \n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence\n",
    "    #print('len:', len(split_list), 'order', order)\n",
    "    #if(order+1>len(split_list)):\n",
    "        #combats_train_hot_label[i][35] = 1\n",
    "        #continue\n",
    "        \n",
    "    for ex in range(add_bidding):\n",
    "        end_1 = ex*4 + order - 1\n",
    "        #print(end_1)\n",
    "        split_list[end_1] = split_list[end_1].replace(\"!\", \"\")\n",
    "        if(split_list[end_1]=='p' or split_list[end_1]=='p!' or split_list[end_1]=='P' or split_list[end_1]=='P!'):\n",
    "            combats_train_hot_label[t][0] = 1\n",
    "\n",
    "        elif(split_list[end_1]=='d' or split_list[end_1]=='d!' or split_list[end_1]=='D' or split_list[end_1]=='D!'):\n",
    "            combats_train_hot_label[t][36] = 1\n",
    "        elif(split_list[end_1]=='r' or split_list[end_1]=='r!' or split_list[end_1]=='R' or split_list[end_1]=='R!'):\n",
    "            combats_train_hot_label[t][37] = 1\n",
    "        temp_num = 0    \n",
    "        if (len(split_list[end_1]) == 2 and split_list[end_1][0].isdigit()):\n",
    "            temp_num = (int(split_list[end_1][0])-1)*5\n",
    "            if(split_list[end_1][1] == 'C' or split_list[end_1][1] == 'c'):\n",
    "                temp_num += 1\n",
    "            elif(split_list[end_1][1] == 'D' or split_list[end_1][1] == 'd' ):\n",
    "                temp_num += 2\n",
    "            elif(split_list[end_1][1] == 'H' or split_list[end_1][1] == 'h'):\n",
    "                temp_num += 3\n",
    "            elif(split_list[end_1][1] == 'S' or split_list[end_1][1] == 's'):\n",
    "                temp_num += 4\n",
    "            elif(split_list[end_1][1] == 'N' or split_list[end_1][1] == 'n'): \n",
    "                temp_num += 5\n",
    "            else:\n",
    "                temp_num = 0\n",
    "            combats_train_hot_label[t][temp_num] = 1 \n",
    "        t += 1\n",
    "    \n",
    "\n",
    "#combats_train_hot_label = np_utils.to_categorical(combats_train_label,2)\n",
    "\n",
    "combats_train_hot_label = np.asarray(combats_train_hot_label)\n",
    "print(t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "(341553, 38)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(combats_train_hot_label[114998][:])\n",
    "print(combats_train_hot_label[114999][:])\n",
    "print(combats_train_hot_label[115000][:])\n",
    "print(combats_train_hot_label)\n",
    "print(combats_train_hot_label.shape)\n",
    "print(type(combats_train_hot_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "(341553, 38)\n"
     ]
    }
   ],
   "source": [
    "#np.savetxt('./data/combats_train_hot_label_save_file_back12_30000.txt', combats_train_hot_label, fmt='%d')\n",
    "combats_train_hot_label = np.loadtxt('./data/combats_train_hot_label_save_file_back12_30000.txt', dtype=int)\n",
    "print(combats_train_hot_label[0])\n",
    "print(combats_train_hot_label[999])\n",
    "print(combats_train_hot_label)\n",
    "print(combats_train_hot_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(341553, 38)\n",
      "<class 'numpy.ndarray'>\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#combats_train_hot_label = to_categorical(combats_train_hot_label,2)\n",
    "#combats_train_hot_label = combats_train_hot_label.astype(float)\n",
    "print(combats_train_hot_label.shape)\n",
    "print(type(combats_train_hot_label))\n",
    "print(combats_train_hot_label[0,:])\n",
    "print(combats_train_hot_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Embedding\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(train_norm[0])\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    ###   code here  #####\n",
    "    #keras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)\n",
    "    \n",
    "    model.add(Dense(64,input_shape = (length,))) #need to check the input size, first set the input node to be 128 as matlab do\n",
    "    model.add(Activation('relu')) #might be leakyRelu, since they used the parameter alpha, still need to check\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \"\"\"\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \"\"\" \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(38,activation='softmax')) #need to check the output size, seems to be 36\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 64)                1472      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 38)                2470      \n",
      "=================================================================\n",
      "Total params: 38,566\n",
      "Trainable params: 37,798\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Train on 307397 samples, validate on 34156 samples\n",
      "Epoch 1/1000\n",
      "307397/307397 [==============================] - 14s 45us/step - loss: 0.0509 - acc: 0.0385 - val_loss: 0.0504 - val_acc: 0.1143\n",
      "Epoch 2/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0462 - acc: 0.1785 - val_loss: 0.0397 - val_acc: 0.2956\n",
      "Epoch 3/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0392 - acc: 0.3093 - val_loss: 0.0350 - val_acc: 0.3663\n",
      "Epoch 4/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0351 - acc: 0.3728 - val_loss: 0.0317 - val_acc: 0.4244\n",
      "Epoch 5/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0322 - acc: 0.4222 - val_loss: 0.0284 - val_acc: 0.4801\n",
      "Epoch 6/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0298 - acc: 0.4641 - val_loss: 0.0265 - val_acc: 0.5140\n",
      "Epoch 7/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0280 - acc: 0.4968 - val_loss: 0.0247 - val_acc: 0.5476\n",
      "Epoch 8/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0265 - acc: 0.5228 - val_loss: 0.0239 - val_acc: 0.5675\n",
      "Epoch 9/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0254 - acc: 0.5424 - val_loss: 0.0234 - val_acc: 0.5811\n",
      "Epoch 10/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0246 - acc: 0.5544 - val_loss: 0.0229 - val_acc: 0.5868\n",
      "Epoch 11/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0240 - acc: 0.5638 - val_loss: 0.0225 - val_acc: 0.5938\n",
      "Epoch 12/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0235 - acc: 0.5711 - val_loss: 0.0224 - val_acc: 0.5928\n",
      "Epoch 13/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0232 - acc: 0.5766 - val_loss: 0.0221 - val_acc: 0.5965\n",
      "Epoch 14/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0229 - acc: 0.5816 - val_loss: 0.0217 - val_acc: 0.6019\n",
      "Epoch 15/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0226 - acc: 0.5852 - val_loss: 0.0216 - val_acc: 0.6035\n",
      "Epoch 16/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0224 - acc: 0.5891 - val_loss: 0.0212 - val_acc: 0.6092\n",
      "Epoch 17/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0221 - acc: 0.5923 - val_loss: 0.0210 - val_acc: 0.6097\n",
      "Epoch 18/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0219 - acc: 0.5946 - val_loss: 0.0210 - val_acc: 0.6083\n",
      "Epoch 19/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0218 - acc: 0.5965 - val_loss: 0.0207 - val_acc: 0.6119\n",
      "Epoch 20/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0216 - acc: 0.5982 - val_loss: 0.0206 - val_acc: 0.6122\n",
      "Epoch 21/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0215 - acc: 0.5996 - val_loss: 0.0207 - val_acc: 0.6109\n",
      "Epoch 22/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0214 - acc: 0.6005 - val_loss: 0.0206 - val_acc: 0.6128\n",
      "Epoch 23/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0214 - acc: 0.6014 - val_loss: 0.0204 - val_acc: 0.6135\n",
      "Epoch 24/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0213 - acc: 0.6020 - val_loss: 0.0205 - val_acc: 0.6129\n",
      "Epoch 25/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0212 - acc: 0.6023 - val_loss: 0.0204 - val_acc: 0.6144\n",
      "Epoch 26/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0212 - acc: 0.6034 - val_loss: 0.0203 - val_acc: 0.6155\n",
      "Epoch 27/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0211 - acc: 0.6040 - val_loss: 0.0203 - val_acc: 0.6149\n",
      "Epoch 28/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0211 - acc: 0.6045 - val_loss: 0.0202 - val_acc: 0.6172\n",
      "Epoch 29/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0210 - acc: 0.6054 - val_loss: 0.0203 - val_acc: 0.6166\n",
      "Epoch 30/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0210 - acc: 0.6057 - val_loss: 0.0202 - val_acc: 0.6179\n",
      "Epoch 31/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0210 - acc: 0.6062 - val_loss: 0.0202 - val_acc: 0.6187\n",
      "Epoch 32/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0209 - acc: 0.6072 - val_loss: 0.0201 - val_acc: 0.6195\n",
      "Epoch 33/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0209 - acc: 0.6077 - val_loss: 0.0201 - val_acc: 0.6206\n",
      "Epoch 34/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0208 - acc: 0.6087 - val_loss: 0.0200 - val_acc: 0.6216\n",
      "Epoch 35/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0208 - acc: 0.6094 - val_loss: 0.0200 - val_acc: 0.6225\n",
      "Epoch 36/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0208 - acc: 0.6102 - val_loss: 0.0199 - val_acc: 0.6239\n",
      "Epoch 37/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0207 - acc: 0.6112 - val_loss: 0.0198 - val_acc: 0.6245\n",
      "Epoch 38/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0207 - acc: 0.6120 - val_loss: 0.0198 - val_acc: 0.6246\n",
      "Epoch 39/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0206 - acc: 0.6121 - val_loss: 0.0198 - val_acc: 0.6251\n",
      "Epoch 40/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0206 - acc: 0.6128 - val_loss: 0.0198 - val_acc: 0.6258\n",
      "Epoch 41/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0205 - acc: 0.6141 - val_loss: 0.0197 - val_acc: 0.6268\n",
      "Epoch 42/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0205 - acc: 0.6144 - val_loss: 0.0197 - val_acc: 0.6275\n",
      "Epoch 43/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0205 - acc: 0.6145 - val_loss: 0.0197 - val_acc: 0.6274\n",
      "Epoch 44/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0205 - acc: 0.6149 - val_loss: 0.0197 - val_acc: 0.6263\n",
      "Epoch 45/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0205 - acc: 0.6148 - val_loss: 0.0196 - val_acc: 0.6284\n",
      "Epoch 46/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0204 - acc: 0.6155 - val_loss: 0.0196 - val_acc: 0.6291\n",
      "Epoch 47/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0204 - acc: 0.6161 - val_loss: 0.0196 - val_acc: 0.6295\n",
      "Epoch 48/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0204 - acc: 0.6163 - val_loss: 0.0196 - val_acc: 0.6294\n",
      "Epoch 49/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0203 - acc: 0.6167 - val_loss: 0.0195 - val_acc: 0.6299\n",
      "Epoch 50/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0203 - acc: 0.6169 - val_loss: 0.0195 - val_acc: 0.6301\n",
      "Epoch 51/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0203 - acc: 0.6171 - val_loss: 0.0195 - val_acc: 0.6314\n",
      "Epoch 52/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0203 - acc: 0.6176 - val_loss: 0.0195 - val_acc: 0.6308\n",
      "Epoch 53/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0202 - acc: 0.6186 - val_loss: 0.0195 - val_acc: 0.6306\n",
      "Epoch 54/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0202 - acc: 0.6184 - val_loss: 0.0195 - val_acc: 0.6313\n",
      "Epoch 55/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0202 - acc: 0.6183 - val_loss: 0.0194 - val_acc: 0.6319\n",
      "Epoch 56/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0202 - acc: 0.6187 - val_loss: 0.0194 - val_acc: 0.6320\n",
      "Epoch 57/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0202 - acc: 0.6190 - val_loss: 0.0194 - val_acc: 0.6326\n",
      "Epoch 58/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0202 - acc: 0.6195 - val_loss: 0.0194 - val_acc: 0.6320\n",
      "Epoch 59/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0202 - acc: 0.6192 - val_loss: 0.0194 - val_acc: 0.6324\n",
      "Epoch 60/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6201 - val_loss: 0.0194 - val_acc: 0.6321\n",
      "Epoch 61/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6200 - val_loss: 0.0194 - val_acc: 0.6331\n",
      "Epoch 62/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6199 - val_loss: 0.0194 - val_acc: 0.6320\n",
      "Epoch 63/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6207 - val_loss: 0.0194 - val_acc: 0.6325\n",
      "Epoch 64/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6208 - val_loss: 0.0193 - val_acc: 0.6334\n",
      "Epoch 65/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6204 - val_loss: 0.0194 - val_acc: 0.6320\n",
      "Epoch 66/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6209 - val_loss: 0.0193 - val_acc: 0.6334\n",
      "Epoch 67/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0200 - acc: 0.6215 - val_loss: 0.0193 - val_acc: 0.6338\n",
      "Epoch 68/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0201 - acc: 0.6211 - val_loss: 0.0193 - val_acc: 0.6336\n",
      "Epoch 69/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0200 - acc: 0.6214 - val_loss: 0.0194 - val_acc: 0.6328\n",
      "Epoch 70/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0200 - acc: 0.6215 - val_loss: 0.0194 - val_acc: 0.6320\n",
      "Epoch 71/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0200 - acc: 0.6218 - val_loss: 0.0193 - val_acc: 0.6331\n",
      "Epoch 72/1000\n",
      "307397/307397 [==============================] - 4s 14us/step - loss: 0.0200 - acc: 0.6219 - val_loss: 0.0193 - val_acc: 0.6329\n",
      "Epoch 00072: early stopping\n"
     ]
    }
   ],
   "source": [
    "############## Start Training ############\n",
    "# use validation_data=(valid_data,valid_labels) in model.fit !!!!!! #\n",
    "'''\n",
    "training parameters\n",
    "update_dnntype = 2; \n",
    "badupdate_dnn = 2; \n",
    "explore_first = 1; \n",
    "alphaupdate_dnn = 0.1;\n",
    "batchsizeupdate_dnn = 50;\n",
    "batchsize = 50;\n",
    "decayRate = 0.98;\n",
    "momentum = 0.82;\n",
    "alpha = 0.83;\n",
    "startbackprop = 0;\n",
    "input = 52+36+5;\n",
    "lsize = 128;\n",
    "layer = 4;\n",
    "output = 36;\n",
    "eta = 0.05;\n",
    "'''\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "model = build_model()\n",
    "#sgd = optimizers.SGD(lr=0.2, clipnor0m=1.0,decay = 1e-08) #original 1e-08)\n",
    "#adadelta = optimizers.Adadelta(lr=1.0, epsilon=None, decay=0.0)\n",
    "model.compile(optimizer=\"adadelta\"#\"adadelta\"\n",
    "            #,loss='categorical_crossentropy'\n",
    "            ,loss='mae'\n",
    "            ,metrics=['accuracy'])\n",
    "\n",
    "record = model.fit(train_norm,combats_train_hot_label\n",
    "                   ,batch_size=4096 #original 64\n",
    "                   ,epochs=1000\n",
    "                   ,validation_split = 0.1\n",
    "                   ,callbacks=[earlyStopping]\n",
    "                   ,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56666/56666 [==============================] - 0s 5us/step\n",
      "Test score: 0.01962980307781698\n",
      "Test acc: 0.6273956162549267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(28338):    check = True\\n    while(check):\\n        check = False\\n        for j in range(int(avoid_data[i][16])-1):\\n            if(pred[i]>=1 and pred[i]<=35):\\n                if(avoid_data[i][j]>pred[i] and avoid_data[i][j]>=1 and avoid_data[i][j]<=35):\\n                    pred_array[i][pred[i]] = 0\\n                    pred[i] = np.argmax(pred_array[i])\\n                    check = True\\n            else:\\n                if(avoid_data[i][j]>pred[i] and (avoid_data[i][j]==36 or avoid_data[i][j]==37)):\\n                    pred_array[i][pred[i]] = 0\\n                    pred[i] = np.argmax(pred_array[i])\\n                    check = True\\n\\n\\ncount = 0\\nfor i in range(28338):\\n    if(pred[i][0]==np.argmax(combats_test_hot_label[i])):\\n        count+=1\\n\\nprint(count/28338)#the test accuracy\\nprint(count)\\n\\n\\nfor i in range(test_data):\\n    pred[i] = np.argmax(model.predict(test_data[i])[:], axis=1)\\n'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### use \"model.predict(testing_data)\" to get the results ######\n",
    "from keras.models import load_model\n",
    "\n",
    "#model = load_model('bridge_model.h5')\n",
    "#pred = np.argmax(model.predict(test_data), axis=1).reshape(len(test_data),1)\n",
    "#pred_array = model.predict(test_data)\n",
    "#predicted_output_df = pd.DataFrame(pred, columns = [\"card output\"])  #predicted output\n",
    "#output = pd.read_csv('bridge_test_output1.csv') #real ouput\n",
    "score, acc = model.evaluate(test_data_onlyfeature_norm, combats_test_hot_label, batch_size=1024)\n",
    "print('Test score:', score)\n",
    "print('Test acc:', acc)\n",
    "#print(pred)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for i in range(28338):    check = True\n",
    "    while(check):\n",
    "        check = False\n",
    "        for j in range(int(avoid_data[i][16])-1):\n",
    "            if(pred[i]>=1 and pred[i]<=35):\n",
    "                if(avoid_data[i][j]>pred[i] and avoid_data[i][j]>=1 and avoid_data[i][j]<=35):\n",
    "                    pred_array[i][pred[i]] = 0\n",
    "                    pred[i] = np.argmax(pred_array[i])\n",
    "                    check = True\n",
    "            else:\n",
    "                if(avoid_data[i][j]>pred[i] and (avoid_data[i][j]==36 or avoid_data[i][j]==37)):\n",
    "                    pred_array[i][pred[i]] = 0\n",
    "                    pred[i] = np.argmax(pred_array[i])\n",
    "                    check = True\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(28338):\n",
    "    if(pred[i][0]==np.argmax(combats_test_hot_label[i])):\n",
    "        count+=1\n",
    "\n",
    "print(count/28338)#the test accuracy\n",
    "print(count)\n",
    "\n",
    "\n",
    "for i in range(test_data):\n",
    "    pred[i] = np.argmax(model.predict(test_data[i])[:], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [13]\n",
      " [28]\n",
      " [28]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [ 0]\n",
      " [28]\n",
      " [28]\n",
      " [ 7]\n",
      " [ 7]\n",
      " [30]\n",
      " [27]\n",
      " [27]\n",
      " [28]\n",
      " [ 6]\n",
      " [18]\n",
      " [36]\n",
      " [ 6]\n",
      " [23]\n",
      " [36]\n",
      " [27]\n",
      " [ 2]\n",
      " [12]\n",
      " [36]\n",
      " [27]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [ 7]\n",
      " [20]\n",
      " [ 4]\n",
      " [ 4]\n",
      " [14]\n",
      " [ 3]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [23]\n",
      " [36]\n",
      " [36]\n",
      " [34]\n",
      " [ 4]\n",
      " [ 7]\n",
      " [34]\n",
      " [ 4]\n",
      " [ 7]\n",
      " [12]\n",
      " [ 1]\n",
      " [ 8]\n",
      " [13]\n",
      " [ 1]\n",
      " [20]\n",
      " [36]\n",
      " [23]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [29]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [37]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [34]\n",
      " [ 5]\n",
      " [36]\n",
      " [34]\n",
      " [ 7]\n",
      " [36]\n",
      " [36]\n",
      " [30]\n",
      " [20]\n",
      " [36]\n",
      " [10]\n",
      " [ 6]\n",
      " [10]\n",
      " [20]\n",
      " [36]\n",
      " [18]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [13]\n",
      " [21]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [13]\n",
      " [36]\n",
      " [27]\n",
      " [ 7]\n",
      " [ 6]\n",
      " [23]\n",
      " [ 6]\n",
      " [18]\n",
      " [ 2]\n",
      " [12]\n",
      " [17]\n",
      " [27]\n",
      " [36]\n",
      " [27]\n",
      " [27]\n",
      " [27]\n",
      " [ 4]\n",
      " [ 9]\n",
      " [14]\n",
      " [ 4]\n",
      " [19]\n",
      " [ 3]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [23]\n",
      " [ 0]\n",
      " [17]\n",
      " [36]\n",
      " [34]\n",
      " [34]\n",
      " [ 1]\n",
      " [ 8]\n",
      " [20]\n",
      " [ 1]\n",
      " [30]\n",
      " [20]\n",
      " [36]\n",
      " [36]\n",
      " [ 0]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [23]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 5]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [37]\n",
      " [ 0]\n",
      " [29]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 4]\n",
      " [19]]\n"
     ]
    }
   ],
   "source": [
    "print(pred[1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./data/bridge_model_back12_800000.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_251_input to have shape (69,) but got array with shape (97,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-b97274ecbb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombats_train_hot_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_251_input to have shape (69,) but got array with shape (97,)"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(train_norm, combats_train_hot_label, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "plt.plot(record.history['acc'],label='acc')\n",
    "plt.plot(record.history['val_acc'],label='val_acc')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(record.history['loss'],label='loss')\n",
    "plt.plot(record.history['val_loss'],label='val_loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import csv\n",
    "bridge_df_test = []\n",
    "\n",
    "bridge_df_test = pd.concat([bridge_dfN_test, bridge_dfS_test], ignore_index=True)\n",
    "bridge_df_test = pd.concat([bridge_df_test, bridge_dfE_test], ignore_index=True)\n",
    "bridge_df_test = pd.concat([bridge_df_test, bridge_dfW_test], ignore_index=True)\n",
    "\n",
    "bridge_df_test.to_csv(\"bridge_test\", encoding='utf-8', index=False)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "(20000, 19)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('bridge_test.csv') \n",
    "#test_df = test_df[:20000]\n",
    "\n",
    "\n",
    "print(len(test_df.iloc[:,:]))\n",
    "print(test_df.iloc[:,:].shape)\n",
    "#print(test_df)\n",
    "\n",
    "test_data=[]\n",
    "test_data_without_feature = []\n",
    "\n",
    "for i in range(len(test_df.iloc[:,:])):\n",
    "    if test_df.iloc[i,1] == 'none':\n",
    "        test_df.iloc[i,1] = 0\n",
    "    elif test_df.iloc[i,1] == 'NS':\n",
    "        test_df.iloc[i,1] = 1\n",
    "    elif test_df.iloc[i,1] == 'EW':\n",
    "        test_df.iloc[i,1] = 2\n",
    "    elif test_df.iloc[i,1] == 'both':\n",
    "        test_df.iloc[i,1] = 3\n",
    "        \n",
    "    temp_list = []\n",
    "    without_feature = []\n",
    "    temp_list.append(bridge_df.iloc[i,0])\n",
    "    without_feature.append(bridge_df.iloc[i,0])\n",
    "    temp_list.append(test_df.iloc[i,1])\n",
    "    without_feature.append(test_df.iloc[i,1])\n",
    "    temp_list.append(bridge_df.iloc[i,2])\n",
    "    without_feature.append(bridge_df.iloc[i,2])\n",
    "    temp_list.append(bridge_df.iloc[i,3])\n",
    "    without_feature.append(bridge_df.iloc[i,3])\n",
    "    temp_list.append(bridge_df.iloc[i,5])\n",
    "    without_feature.append(bridge_df.iloc[i,5])\n",
    "\n",
    "    split_list6 = test_df.iloc[i,6].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list6[j])\n",
    "    '''\n",
    "    split_list7 = test_df.iloc[i,7].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list7[j])\n",
    "    '''\n",
    "    split_list9 = test_df.iloc[i,9].split('|')    \n",
    "    for j in range(4):\n",
    "        suit = [0]*13\n",
    "        for k in range(len(split_list9[j])):\n",
    "            if split_list9[j][k] == 'A':\n",
    "                suit[1] = 1\n",
    "            elif split_list9[j][k] == 'K':\n",
    "                suit[0] = 1\n",
    "            elif split_list9[j][k] == 'Q':\n",
    "                suit[12] = 1\n",
    "            elif split_list9[j][k] == 'J':\n",
    "                suit[11] = 1\n",
    "            elif split_list9[j][k] == 'T':\n",
    "                suit[10] = 1\n",
    "            elif split_list9[j][k].isdigit():\n",
    "                suit[int(split_list9[j][k])] = 1\n",
    "            else:\n",
    "                suit[k] = -1\n",
    "        without_feature = without_feature + suit\n",
    "        temp_list = temp_list + suit\n",
    "        \n",
    "    split_list10 = test_df.iloc[i,10].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list10[j])\n",
    "    temp_list.append(test_df.iloc[i,11])\n",
    "    \n",
    "    split_list12 = test_df.iloc[i,12].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list12[j])\n",
    "    split_list13 = test_df.iloc[i,13].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list13[j])\n",
    "    split_list14 = test_df.iloc[i,14].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list14[j])\n",
    "    split_list15 = test_df.iloc[i,15].split('|')\n",
    "    for j in range(4):\n",
    "        temp_list.append(split_list15[j])\n",
    "    \n",
    "    temp_list.append(test_df.iloc[i,16])\n",
    "    temp_list.append(test_df.iloc[i,17])\n",
    "    if(test_df.iloc[i,18] == 'N'):\n",
    "        temp_list.append(0)\n",
    "    elif(test_df.iloc[i,18] == 'S'):\n",
    "        temp_list.append(1)\n",
    "    elif(test_df.iloc[i,18] == 'E'):\n",
    "        temp_list.append(2)\n",
    "    elif(test_df.iloc[i,18] == 'W'):\n",
    "        temp_list.append(3)\n",
    "    else:\n",
    "        temp_list.append(-1)        \n",
    "              \n",
    "    order = test_df.iloc[i,5]    \n",
    "    split_list = test_df.iloc[i,4].split('|')\n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence    \n",
    "\n",
    "    for ex in range(add_bidding):\n",
    "        temp = 0\n",
    "        temp_list_bidding =[-1]*12\n",
    "        end_1 = ex*4 + order - 1 # split_list[end_1] is the bidding choice of this player in this round \n",
    "        #print('end_1: ', end_1)\n",
    "        #lenth_1 = len(split_list)-1\n",
    "        for j in range(end_1):\n",
    "            if(j>11):\n",
    "                break\n",
    "            split_list[end_1-j-1] = split_list[end_1-j-1].replace(\"!\", \"\")\n",
    "            #print(split_list[end_1-j-1])\n",
    "            if(split_list[end_1-j-1][0]=='p' or split_list[end_1-j-1][0]=='P'):\n",
    "                temp_list_bidding[11-j]=0\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='d' or split_list[end_1-j-1][0]=='D'):\n",
    "                temp_list_bidding[11-j]=36\n",
    "                continue\n",
    "            if(split_list[end_1-j-1][0]=='r' or split_list[end_1-j-1][0]=='R'):\n",
    "                temp_list_bidding[11-j]=37\n",
    "                continue\n",
    "\n",
    "\n",
    "            temp = 0\n",
    "            if(len(split_list[end_1-j-1]) != 2):\n",
    "                temp = -1\n",
    "                break\n",
    "            if(split_list[end_1-j-1][0].isdigit()):\n",
    "                temp += (int(split_list[end_1-j-1][0])-1)*5\n",
    "            if(split_list[end_1-j-1][1] == 'C' or split_list[end_1-j-1][1] == 'c'):\n",
    "                temp += 1\n",
    "            elif(split_list[end_1-j-1][1] == 'D' or split_list[end_1-j-1][1] == 'd' ):\n",
    "                temp += 2\n",
    "            elif(split_list[end_1-j-1][1] == 'H' or split_list[end_1-j-1][1] == 'h'):\n",
    "                temp += 3\n",
    "            elif(split_list[end_1-j-1][1] == 'S' or split_list[end_1-j-1][1] == 's'):\n",
    "                temp += 4\n",
    "            elif(split_list[end_1-j-1][1] == 'N' or split_list[end_1-j-1][1] == 'n'):\n",
    "                temp += 5\n",
    "            else:\n",
    "                temp = -1\n",
    "                break\n",
    "            temp_list_bidding[11-j] = temp\n",
    "            \n",
    "        example = temp_list.copy()\n",
    "        example_without_fea =  without_feature.copy()\n",
    "        for j in range(12):\n",
    "            example.append(temp_list_bidding[j])\n",
    "            example_without_fea.append(temp_list_bidding[j])\n",
    "        test_data.append(example)\n",
    "        test_data_without_feature.append(example_without_fea)\n",
    "\n",
    "test_data = np.asarray(test_data)\n",
    "test_data_without_feature = np.asarray(test_data_without_feature)\n",
    "test_data = test_data.astype('float')\n",
    "test_data_without_feature = test_data_without_feature.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56666, 97)\n",
      "[ 1.  0.  0.  0.  1.  4.  5.  3.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  2.  4.  0.  4. 10.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  1.  3.  0.  1.  5.  2.  0. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1.  0.  4.]\n",
      "EW\n",
      "(56666, 22)\n",
      "[ 0.  4.  4.  3.  2.  2.  1.  1.  0.  0. -1. -1. -1. -1. -1.  4.  0.  7.\n",
      "  0.  8.  0. 10.]\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "print(test_data[5])\n",
    "print(bridge_df.iloc[5,1])\n",
    "l = len(test_data)\n",
    "test_data_onlyfeature  = np.zeros((l,22))#only contain 2 3 6 8 12 features in our paper\n",
    "for i in range(l):\n",
    "    test_data_onlyfeature[i][0] = test_data[i][2]\n",
    "    test_data_onlyfeature[i][1:5] = test_data[i][5:9]\n",
    "    test_data_onlyfeature[i][5] = test_data[i][65]\n",
    "    test_data_onlyfeature[i][6:10] = test_data[i][78:82]\n",
    "    test_data_onlyfeature[i][10:23] = test_data[i][85:97]\n",
    "\n",
    "\n",
    "test_data_onlyfeature = test_data_onlyfeature.astype('float')\n",
    "print(test_data_onlyfeature.shape)\n",
    "print(test_data_onlyfeature[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.  2.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "[ 9.  2.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0. -1. -1. -1. -1. -1. -1. -1. -1.  4.  0. 10.  0.]\n",
      "[ 9.  2.  0.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0. -1. -1. -1. -1.  4.  0. 10.  0. 11.  0. 19.  0.]\n",
      "[[ 1.  0.  0. ...  4.  0.  7.]\n",
      " [ 1.  0.  0. ...  8.  0. 10.]\n",
      " [ 1.  0.  0. ... 15.  0. 17.]\n",
      " ...\n",
      " [24.  0.  0. ... -1. -1.  4.]\n",
      " [24.  0.  0. ... 10.  0. 11.]\n",
      " [24.  0.  0. ... 19.  0.  0.]]\n",
      "(56666, 69)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_without_feature[28335])\n",
    "print(test_data_without_feature[28336])\n",
    "print(test_data_without_feature[28337])\n",
    "print(test_data_without_feature)\n",
    "print(test_data_without_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  3.  0. ...  4.  0.  7.]\n",
      " [ 1.  3.  0. ...  8.  0. 10.]\n",
      " [ 1.  3.  0. ... 15.  0. 17.]\n",
      " ...\n",
      " [24.  0.  0. ... -1. -1.  4.]\n",
      " [24.  0.  0. ... 10.  0. 11.]\n",
      " [24.  0.  0. ... 19.  0.  0.]] [[ 0.07980869  0.23942607  0.         ...  0.31923475  0.\n",
      "   0.55866082]\n",
      " [ 0.0561656   0.16849679  0.         ...  0.44932477  0.\n",
      "   0.56165596]\n",
      " [ 0.03477341  0.10432022  0.         ...  0.52160111  0.\n",
      "   0.59114792]\n",
      " ...\n",
      " [ 0.85847842  0.          0.         ... -0.03576993 -0.03576993\n",
      "   0.14307974]\n",
      " [ 0.75949272  0.          0.         ...  0.3164553   0.\n",
      "   0.34810083]\n",
      " [ 0.6518557   0.          0.         ...  0.51605243  0.\n",
      "   0.        ]] (56666, 97)\n",
      "[[ 1.  3.  0. ...  4.  0.  7.]\n",
      " [ 1.  3.  0. ...  8.  0. 10.]\n",
      " [ 1.  3.  0. ... 15.  0. 17.]\n",
      " ...\n",
      " [24.  0.  0. ... -1. -1.  4.]\n",
      " [24.  0.  0. ... 10.  0. 11.]\n",
      " [24.  0.  0. ... 19.  0.  0.]] [[ 0.10101525  0.30304576  0.         ...  0.40406102  0.\n",
      "   0.70710678]\n",
      " [ 0.06225728  0.18677184  0.         ...  0.49805825  0.\n",
      "   0.62257281]\n",
      " [ 0.03608439  0.10825318  0.         ...  0.54126588  0.\n",
      "   0.61343466]\n",
      " ...\n",
      " [ 0.96386319  0.          0.         ... -0.04016097 -0.04016097\n",
      "   0.16064387]\n",
      " [ 0.82956136  0.          0.         ...  0.34565056  0.\n",
      "   0.38021562]\n",
      " [ 0.6945589   0.          0.         ...  0.54985913  0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#ttt = np.append(traintest_data)\n",
    "#avoid_data = test_data\n",
    "test_norm = normalizer.transform(test_data)\n",
    "test_without_feature_norm = normalizer.transform(test_data_without_feature)\n",
    "print(test_data, test_norm,test_data.shape)\n",
    "print(test_data_without_feature, test_without_feature_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.35777088  0.35777088 ...  0.35777088  0.\n",
      "   0.62609903]\n",
      " [ 0.          0.23693955  0.23693955 ...  0.4738791   0.\n",
      "   0.59234888]\n",
      " [ 0.          0.14186538  0.14186538 ...  0.53199518  0.\n",
      "   0.60292787]\n",
      " ...\n",
      " [ 0.          0.          0.41442434 ... -0.08288487 -0.08288487\n",
      "   0.33153947]\n",
      " [ 0.          0.          0.26259023 ...  0.52518046  0.\n",
      "   0.57769851]\n",
      " [ 0.          0.          0.18639564 ...  0.70830342  0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_data_onlyfeature_norm = normalizer.transform(test_data_onlyfeature)\n",
    "print(test_data_onlyfeature_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make testing data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c9f3dfa6d1c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombats_test_hot_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombats_test_hot_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "combats_test_hot_label = [[0 for x in range(38)] for y in range(len(test_data))]\n",
    "print(type(combats_test_hot_label))\n",
    "t = 0\n",
    "\n",
    "for i in range(len(test_df.iloc[:,:])):\n",
    "    split_list = test_df.iloc[i,4].split('|')\n",
    "    order = test_df.iloc[i,5]\n",
    "    \n",
    "    if(len(split_list)%4-order >= 0):\n",
    "        remain = 1\n",
    "    else:\n",
    "        remain = 0\n",
    "    add_bidding = int(len(split_list)/4) + remain #can cut into how many examples for one bidding seqence\n",
    "    #print('len:', len(split_list), 'order', order)\n",
    "    #if(order+1>len(split_list)):\n",
    "        #combats_train_hot_label[i][35] = 1\n",
    "        #continue\n",
    "        \n",
    "    for ex in range(add_bidding):\n",
    "        end_1 = ex*4 + order - 1\n",
    "        #print(end_1)\n",
    "        split_list[end_1] = split_list[end_1].replace(\"!\", \"\")\n",
    "        if(split_list[end_1]=='p' or split_list[end_1]=='p!' or split_list[end_1]=='P' or split_list[end_1]=='P!'):\n",
    "            combats_test_hot_label[t][0] = 1\n",
    "\n",
    "        elif(split_list[end_1]=='d' or split_list[end_1]=='d!' or split_list[end_1]=='D' or split_list[end_1]=='D!'):\n",
    "            combats_test_hot_label[t][36] = 1\n",
    "        elif(split_list[end_1]=='r' or split_list[end_1]=='r!' or split_list[end_1]=='R' or split_list[end_1]=='R!'):\n",
    "            combats_test_hot_label[t][37] = 1\n",
    "        temp_num = 0    \n",
    "        if (len(split_list[end_1]) == 2 and split_list[end_1][0].isdigit()):\n",
    "            temp_num = (int(split_list[end_1][0])-1)*5\n",
    "            if(split_list[end_1][1] == 'C' or split_list[end_1][1] == 'c'):\n",
    "                temp_num += 1\n",
    "            elif(split_list[end_1][1] == 'D' or split_list[end_1][1] == 'd' ):\n",
    "                temp_num += 2\n",
    "            elif(split_list[end_1][1] == 'H' or split_list[end_1][1] == 'h'):\n",
    "                temp_num += 3\n",
    "            elif(split_list[end_1][1] == 'S' or split_list[end_1][1] == 's'):\n",
    "                temp_num += 4\n",
    "            elif(split_list[end_1][1] == 'N' or split_list[end_1][1] == 'n'): \n",
    "                temp_num += 5\n",
    "            else:\n",
    "                temp_num = 0\n",
    "            combats_test_hot_label[t][temp_num] = 1 \n",
    "        t += 1\n",
    "    \n",
    "\n",
    "#combats_train_hot_label = np_utils.to_categorical(combats_train_label,2)\n",
    "\n",
    "combats_test_hot_label = np.asarray(combats_test_hot_label)\n",
    "#combats_test_hot_label = combats_test_hot_label.astype(float)\n",
    "print(t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(combats_test_hot_label[28335])\n",
    "print(combats_test_hot_label[28336])\n",
    "print(combats_test_hot_label[28337])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_data[:,0] = test_data[:,0]/50\n",
    "test_data[:,1] = test_data[:,1]/3\n",
    "test_data[:,4:15] = test_data[:,4:15]/37\n",
    "test_data[:,16] = test_data[:,16]/4\n",
    "test_data[:,17:20] = test_data[:,17:20]/13\n",
    "test_data[:,73:76] = test_data[:,73:76]/13\n",
    "test_data[:,81] = test_data[:,81]/30\n",
    "test_data[:,91:94] = test_data[:,91:94]/10\n",
    "test_data[:,95] = test_data[:,95]/10\n",
    "test_data[:,96] = test_data[:,96]/10\n",
    "\n",
    "\n",
    "print(test_data.shape)\n",
    "print(type(test_data))\n",
    "print(test_data[0,:])\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.asarray(output)\n",
    "test_data = np.asarray(test_data)\n",
    "predicted_output_df = np.asarray(predicted_output_df)\n",
    "\n",
    "temp = [[0 for x in range(38)] for y in range(20000)]\n",
    "\n",
    "for i in range(len(output)):\n",
    "    temp[i][int(output[i])] = 1\n",
    "\n",
    "\n",
    "\n",
    "score= model.evaluate(test_data, ground[:19999], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the result to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv',index_label = \"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 317,
   "position": {
    "height": "229px",
    "left": "1293px",
    "right": "20px",
    "top": "156px",
    "width": "623px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
